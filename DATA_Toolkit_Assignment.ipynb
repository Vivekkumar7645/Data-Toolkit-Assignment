{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DATA Toolkit Assignment"
      ],
      "metadata": {
        "id": "M8VePUt2vOyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 1. What is NumPy, and why is it widely used in Python?\n",
        "**Ans** - NumPy is a popular open-source library in Python that provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
        "\n",
        "**Reasons why NumPy is widely used:**\n",
        "1. **Efficient Array Operations**:\n",
        "* NumPy provides a powerful N-dimensional array object that is more efficient in terms of memory and speed compared to traditional Python lists.\n",
        "* Operations on NumPy arrays are performed element-wise, which is much faster.\n",
        "\n",
        "2. **Broadcasting**:\n",
        "* NumPy allows operation on arrays of different shapes, automatically expanding them to compatible shapes, making it easier to perform operations without needing to write explicit loops.\n",
        "\n",
        "3. **Mathematical Functions**:\n",
        "* NumPy includes a wide range of mathematical functions for operations like linear algebra, Fourier transforms, and statistical computations.\n",
        "\n",
        "4. **Integration with Other Libraries**:\n",
        "* Many other scientific and data analysis libraries (e.g., SciPy, pandas, scikit-learn) are built on top of or are compatible with NumPy arrays, facilitating integration and ease of use in a broader data science and scientific computing ecosystem.\n",
        "\n",
        "5. **Data Handling**:\n",
        "NumPy arrays can be used to efficiently handle large datasets, making it a fundamental tool for data analysis, machine learning, and scientific computing.\n",
        "\n",
        "6. **Ease of Use**:\n",
        "* Its syntax and functions are easy to learn and use, allowing developers and researchers to write concise and readable code.\n",
        "\n",
        "7. **Community and Documentation**:\n",
        "* NumPy has a large community of users and contributors, and it is well-documented, making it easier for newcomers to get started and for experienced users to find help and resources."
      ],
      "metadata": {
        "id": "7C8C0WnhvVAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 2. How does broadcasting work in NumPy?\n",
        "**Ans** - Broadcasting in NumPy is a mechanism that allows operations on arrays of different shapes, enabling efficient vectorized computation without explicitly reshaping arrays or writing loops.\n",
        "\n",
        "1. **Basic Broadcasting Rules**:\n",
        "* Rule 1: If the arrays have different number of dimensions, the shape of the smaller array is padded with ones on its left side until both shapes have the same number of dimensions.\n",
        "* Rule 2: Arrays are compatible for broadcasting if, for each dimension, the sizes match, or one of the size is 1.\n",
        "* Rule 3: If one of the dimensions is 1, the array can be stretched or \"broadcast\" to match the other array's size in that dimension.\n",
        "\n",
        "2. **Examples**:\n",
        "* Example 1: Scalar and Array"
      ],
      "metadata": {
        "id": "jvsSIQC3vnaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "array = np.array([1, 2, 3])\n",
        "scalar = 2\n",
        "result = array + scalar"
      ],
      "metadata": {
        "id": "RKi8v2lwWEX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Example 2: Two Arrays"
      ],
      "metadata": {
        "id": "oDNt3SunWdni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([[1], [2], [3]])\n",
        "result = array1 + array2"
      ],
      "metadata": {
        "id": "CvmG-I3UWFii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Example 3: Arrays with Different Shapes"
      ],
      "metadata": {
        "id": "Pn-xK-C8WjbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "array2 = np.array([10, 20, 30])\n",
        "result = array1 + array2"
      ],
      "metadata": {
        "id": "dtUZWoDqWE-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Advantages of Broadcasting**:\n",
        "* Efficiency: Broadcasting allows for vectorized operations, reducing the need for explicit loops and making computations faster.\n",
        "* Code Simplification: It simplifies code by eliminating the need to manually reshape or replicate arrays."
      ],
      "metadata": {
        "id": "gRNs_1VaWomi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 3. What is a Pandas DataFrame?\n",
        "**Ans**- A **Pandas DataFrame** is a two-dimensional, size-mutable, and heterogeneous data structure in Python, similar to a table in a database, an Excel spreadsheet, or a data frame in R. It is one of the core data structures provided by the Pandas library and is widely used for data manipulation and analysis.\n",
        "\n",
        "Features and usage:\n",
        "1. **Structure**:\n",
        "* Rows and Columns: A DataFrame is composed of rows and columns. Each column can hold different types of data like - numeric, string, datetime, etc..\n",
        "* Indices: It has a row index and a column index, allowing easy access to data by labels or positions.\n",
        "2. **Creation** : We can create a DataFrame in various ways.\n",
        "* From Dictionaries:"
      ],
      "metadata": {
        "id": "igcvses2v-Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'Name': ['Vivek', 'Vikash', 'Vinay'],\n",
        "        'Age': [25, 30, 35],\n",
        "        'City': ['Dhanbad', 'Bokaro', 'Giridih']}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "1kTqY2P7XVlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From Lists of Lists:"
      ],
      "metadata": {
        "id": "ntS-Kq_MYD2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [['Vivek', 25, 'Dhanbad'], ['Vikash', 30, 'Bokaro'], ['Vinay', 35, 'Giridih']]\n",
        "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])"
      ],
      "metadata": {
        "id": "bcR4zuJPXWqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From NumPy Arrays:"
      ],
      "metadata": {
        "id": "OMLqqefTYALS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C'])"
      ],
      "metadata": {
        "id": "84nzgHkhXWf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Key Features**:\n",
        "* Heterogeneous Data: Can hold different types of data in each column.\n",
        "* Label-based Indexing: Access data using labels (df['column_name']) or position-based indexing (df.iloc[0]).\n",
        "* Alignment: Automatically aligns data in computations based on labels.\n",
        "* Missing Data Handling: Provides functionalities like fillna(), dropna(), and more for handling missing data.\n",
        "\n",
        "4. **Common Operations**:\n",
        "* Selection: df['column_name'], df.loc['row_label'], df.iloc[row_index]\n",
        "* Filtering: df[df['column_name'] > value]\n",
        "* Aggregation: df.groupby('column_name').mean()\n",
        "* Merging/Joining: pd.merge(df1, df2, on='key')\n",
        "* Reshaping: df.pivot(), df.melt()\n",
        "* Reading/Writing Data: Supports reading from and writing to various file formats like CSV, Excel, SQL, JSON, etc.\n",
        "\n",
        "5. **Usage**:\n",
        "\n",
        "Pandas DataFrames are widely used for:\n",
        "* Data cleaning and preparation.\n",
        "* Data exploration and analysis.\n",
        "* Data visualization (often used with libraries like Matplotlib or Seaborn).\n",
        "* Importing and exporting data to/from different formats.\n",
        "\n",
        "6. **Example**:"
      ],
      "metadata": {
        "id": "YctkGTLNX5OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'Name': ['Vivek', 'Vikash', 'Vinay'],\n",
        "        'Age': [25, 30, 35],\n",
        "        'City': ['Dhanbad', 'Bokaro', 'Giridih']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df['Name'])\n",
        "print(df[df['Age'] > 25])"
      ],
      "metadata": {
        "id": "9ohCug-FXWQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 4.Explain the use of the groupby() method in Pandas?\n",
        "**Ans** - The groupby() method in Pandas is a powerful tool for grouping data based on one or more keys and performing aggregate functions on the grouped data. It is commonly used for data summarization, aggregation, and transformation tasks.\n",
        "\n",
        "1. **Basic Syntax:**"
      ],
      "metadata": {
        "id": "1Kd3HOyzwBHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)"
      ],
      "metadata": {
        "id": "DUvEJ93IY6bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Parameters**:\n",
        "* by: Specifies the column(s) or index level(s) to group by. It can be a string, list of strings, or a function.\n",
        "* axis: Determines whether to group along rows (axis=0, default) or columns (axis=1).\n",
        "* level: Specifies the level(s) if grouping by a MultiIndex.\n",
        "* as_index: If True, the group labels are set as the index. If False, the group labels are kept as columns.\n",
        "* sort: If True, groups are sorted by their keys.\n",
        "* group_keys: If True, adds group keys to the index by default.\n",
        "* observed: If True and grouping by categorical data, only the observed groups are returned.\n",
        "* dropna: If True, drop groups with missing values.\n",
        "\n",
        "3. **Common Operations**:\n",
        "* Grouping by a Single Column:"
      ],
      "metadata": {
        "id": "6D9dhff2ZA7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('column_name')"
      ],
      "metadata": {
        "id": "Y5ehWw5fZKuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Grouping by Multiple Columns:"
      ],
      "metadata": {
        "id": "3VjF6IGDZMWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['column1', 'column2'])"
      ],
      "metadata": {
        "id": "Ml5IBYzHZc1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Applying Aggregate Functions:"
      ],
      "metadata": {
        "id": "iyLC-cr5Zejt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('column_name').sum()\n",
        "df.groupby('column_name').mean()\n",
        "df.groupby('column_name').count()"
      ],
      "metadata": {
        "id": "P1ufWTM0ZlR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Examples**:\n",
        "* Example 1: Basic Grouping and Summation"
      ],
      "metadata": {
        "id": "dE1qSEPAZqpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'Team': ['A', 'A', 'B', 'B', 'A'],\n",
        "        'Points': [10, 15, 10, 20, 10],\n",
        "        'City': ['NY', 'NY', 'LA', 'LA', 'NY']}\n",
        "df = pd.DataFrame(data)\n",
        "grouped = df.groupby('Team')\n",
        "print(grouped.sum())"
      ],
      "metadata": {
        "id": "WwP9H3NRZw5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Example 2: Grouping by Multiple Columns\n"
      ],
      "metadata": {
        "id": "GMFMYbwnaEyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby(['Team', 'City']).sum()\n",
        "print(grouped)"
      ],
      "metadata": {
        "id": "mxIK3t6VaxqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 3: Applying Multiple Aggregations"
      ],
      "metadata": {
        "id": "oGiZccjhbMPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby('Team').agg({'Points': ['sum', 'mean', 'max']})\n",
        "print(grouped)"
      ],
      "metadata": {
        "id": "jhAjFiIkbWaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 4: Transforming Grouped Data"
      ],
      "metadata": {
        "id": "q9l5qtpKbckE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed = df.groupby('Team')['Points'].transform('sum')\n",
        "print(transformed)"
      ],
      "metadata": {
        "id": "UxRvbb8-bixD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 5. Why is Seaborn preferred for statistical visualizations?\n",
        "**Ans** - Seaborn is preferred for statistical visualizations due to its ability to create aesthetically pleasing and informative graphics with minimal effort. It builds on top of Matplotlib and integrates closely with Pandas, making it particularly well-suited for data exploration and analysis.\n",
        "\n",
        "**Reasons for Seaborn is favored for statistical visualizations:**\n",
        "1. **High-Level Interface**:\n",
        "* Simplified Syntax: Seaborn provides a high-level interface for drawing attractive and informative statistical graphics. This makes it easier to create complex visualizations with less code compared to Matplotlib.\n",
        "* Built-in Themes: Seaborn comes with several built-in themes and color palettes to make visualizations visually appealing and easier to interpret.\n",
        "\n",
        "2. **Integration with Pandas**:\n",
        "* Ease of Use with DataFrames: Seaborn works seamlessly with Pandas DataFrames, allowing users to pass DataFrame columns directly into plotting functions. This makes it straightforward to create plots from structured data.\n",
        "* Automatic Handling of Missing Data: Seaborn can handle missing data gracefully, often excluding it automatically from plots without requiring manual intervention.\n",
        "\n",
        "3. **Advanced Statistical Plots**:\n",
        "* Built-in Statistical Functions: Seaborn provides functions for complex statistical plots, including:\n",
        "  * scatterplot(), lineplot() for basic plots.\n",
        "  * boxplot(), violinplot(), swarmplot() for distribution and categorical data.\n",
        "  * heatmap() for visualizing matrix-style data.\n",
        "  * pairplot() for plotting pairwise relationships in a dataset.\n",
        "  * jointplot() for combined plots showing both scatter and distribution.\n",
        "\n",
        "* Statistical Estimations: Many Seaborn functions can automatically perform statistical transformations, like fitting regression models (regplot(), lmplot()), showing confidence intervals, and computing aggregated statistics.\n",
        "\n",
        "4. **Customization and Aesthetics**:\n",
        "* Theme Control: Seaborn offers various themes (darkgrid, whitegrid, dark, white, ticks) to change the overall appearance of plots with a single command (sns.set_theme()).\n",
        "* Color Palettes: It provides a rich set of color palettes (deep, muted, bright, pastel, dark, colorblind) that can be easily customized and applied to plots.\n",
        "* Customization Options: While providing sensible defaults, Seaborn allows extensive customization for fine-tuning plots.\n",
        "\n",
        "5. **Efficient Visualization of Large Datasets**:\n",
        "* Facet Grids: Seaborn’s FacetGrid allows you to create multi-plot grids for visualizing subsets of data based on different conditions, making it easy to compare multiple variables or categories in a structured way.\n",
        "\n",
        "6. **Ease of Learning and Use**:\n",
        "* User-Friendly Documentation: Seaborn has well-structured documentation and tutorials that help users quickly get started and understand its capabilities.\n",
        "* Consistent API: The consistent and intuitive API design helps users easily remember function calls and parameters.\n",
        "\n",
        "7. **Community and Support**:\n",
        "* Active Community: Seaborn has a large and active user community, which contributes to continuous improvement and provides ample resources for learning and troubleshooting.\n",
        "\n",
        "**Example of Seaborn Usage**:"
      ],
      "metadata": {
        "id": "Rlb0lo4NwD4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
        "    'Value': [4, 5, 6, 7, 8, 9]\n",
        "})\n",
        "sns.boxplot(x='Category', y='Value', data=data)"
      ],
      "metadata": {
        "id": "WX_kiRSkdF2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 6. What are the differences between NumPy arrays and Python lists?\n",
        "**Ans** - NumPy arrays and Python lists are both used to store collections of data, but they have significant differences in terms of functionality, performance, and use cases.\n",
        "\n",
        "Difference between Numpy arrays and python lists:\n",
        "1. **Data Type Consistency**:\n",
        "* NumPy Arrays: All elements in a NumPy array must be of the same data type. This uniformity allows NumPy to perform operations more efficiently.\n",
        "* Python Lists: Python lists can contain elements of different data types. This flexibility however, can lead to less efficient operations.\n",
        "\n",
        "2. **Performance**:\n",
        "* NumPy Arrays: NumPy arrays are implemented in C, which makes them much faster and more efficient for numerical computations. They take up less memory and provide better performance, especially for large datasets and mathematical operations.\n",
        "* Python Lists: Python lists are slower because they are more general-purpose and do not have the same optimizations as NumPy arrays for numerical computations.\n",
        "\n",
        "3. **Operations**:\n",
        "* NumPy Arrays: Support element-wise operations, vectorized operations, and broadcasting. This allows for concise and efficient mathematical computations."
      ],
      "metadata": {
        "id": "2zY1xOMuwF2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "result = a + b"
      ],
      "metadata": {
        "id": "YfSed-ZveGNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Python Lists: Operations like addition concatenate lists instead of performing element-wise addition."
      ],
      "metadata": {
        "id": "R6lipb30eIJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3]\n",
        "b = [4, 5, 6]\n",
        "result = a + b"
      ],
      "metadata": {
        "id": "S5mPosUTeSJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Memory Efficiency:**\n",
        "* NumPy Arrays: Use less memory due to their homogeneous data type and efficient storage layout.\n",
        "* Python Lists: Use more memory because they store pointers to Python objects and need to handle heterogeneous data types.\n",
        "\n",
        "5. **Functionality:**\n",
        "* NumPy Arrays: Provide numerous built-in functions for numerical operations and advanced indexing capabilities.\n",
        "* Python Lists: Do not have built-in functions for mathematical operations and require external libraries or manual implementation for such functionalities.\n",
        "\n",
        "6. **Dimensionality:**\n",
        "* NumPy Arrays: Can have multiple dimensions (1D, 2D, 3D, etc.), making them suitable for handling complex data structures like matrices and tensors.\n",
        "* Python Lists: Can also be nested to create multi-dimensional structures, but this is less intuitive and less efficient compared to NumPy arrays.\n",
        "\n",
        "7. **Use Cases**:\n",
        "* NumPy Arrays: Ideal for scientific computing, data analysis, machine learning, and other scenarios requiring efficient numerical computation.\n",
        "* Python Lists: Suitable for general-purpose use cases where the flexibility of mixed data types is needed and performance is less critical.\n",
        "\n",
        "8. **Indexing and Slicing:**\n",
        "* NumPy Arrays: Support advanced indexing, slicing, and broadcasting."
      ],
      "metadata": {
        "id": "HEnwr82yeWjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(a[:, 1])"
      ],
      "metadata": {
        "id": "oEAJ7-iBe1Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Python Lists: Support basic indexing and slicing."
      ],
      "metadata": {
        "id": "s-K8UfGBe242"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "print([row[1] for row in a])"
      ],
      "metadata": {
        "id": "16W8kz9Ce_BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Feature\t|NumPy Arrays\t|Python Lists|\n",
        "|---|----|----|\n",
        "|Data Type Consistency |Homogeneous\t|Heterogeneous|\n",
        "|Performance\t|Faster\t|Slower|\n",
        "|Operations\t|Element-wise, vectorized\t|Element-wise requires loops|\n",
        "|Memory Efficiency\t|More efficient\t|Less efficient|\n",
        "|Functionality\t|Extensive numerical functions\t|Limited built-in functions|\n",
        "|Dimensionality\t|Multi-dimensional\t|Nested lists|\n",
        "|Use Cases\t|Scientific computing\t|General-purpose|\n",
        "|Indexing and Slicing\t|Advanced\t|Basic|"
      ],
      "metadata": {
        "id": "xu-K300efCyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 7. What is a heatmap, and when should it be used?\n",
        "**Ans** - A heatmap is a data visualization technique that uses color to represent the magnitude of values in a matrix or data table. Each cell in the matrix corresponds to a value, and the color of the cell reflects the magnitude of that value.\n",
        "\n",
        "Typically using a gradient or a color map.\n",
        "\n",
        "**Structure of a Heatmap:**\n",
        "* Axes: The x-axis and y-axis represent different categories or variables.\n",
        "* Cells: Each cell represents the value of the intersection of the x and y categories.\n",
        "* Color Gradient: The color intensity or hue in each cell represents the magnitude of the data point, with different colors indicating different ranges of values.\n",
        "\n",
        "**When to Use a Heatmap**:\n",
        "* Visualizing Complex Data: Heatmaps are particularly useful for visualizing data with a large number of variables and data points, making it easier to identify patterns, correlations, and anomalies.\n",
        "* Correlation Analysis: Heatmaps are commonly used to display correlation matrices, showing the relationship between different variables in a dataset.\n",
        "* Frequency Distribution: They can display the frequency of events or occurrences across different categories.\n",
        "* Comparison of Values: Heatmaps make it easy to compare large amounts of data at a glance, highlighting high and low values through color intensity.\n",
        "* Matrix Data Representation: Useful for representing matrix-like data such as confusion matrices in machine learning, or adjacency matrices in network analysis.\n",
        "\n",
        "3. **Examples of Heatmap Applications:**\n",
        "* Correlation Matrix:"
      ],
      "metadata": {
        "id": "WtuN7qe_wKJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6]\n",
        "})\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "phdpm3C1fuFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Confusion Matrix in Machine Learning:"
      ],
      "metadata": {
        "id": "kbBe7M0jf0WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "confusion_matrix = np.array([[50, 10], [5, 35]])\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')"
      ],
      "metadata": {
        "id": "toxIvo8pf8ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of Using Heatmaps:**\n",
        "* Easy Identification of Patterns: They allow for quick visual identification of patterns, trends, and outliers in the data.\n",
        "* Effective for Large Datasets: Heatmaps are efficient in displaying data when there are many variables, as the visual density can convey information clearly.\n",
        "* Intuitive Understanding: The use of color gradients makes it intuitive to understand the magnitude of values and their relationships."
      ],
      "metadata": {
        "id": "lI9JOyj7f_s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 8. What does the term “vectorized operation” mean in NumPy?\n",
        "**Ans** - The term \"vectorized operation\" in NumPy refers to the process of applying operations simultaneously to entire arrays or vectors without the need for explicit loops. This concept leverages NumPy’s internal optimized C code to perform fast and efficient computations on entire arrays.\n",
        "\n",
        "**Characteristics of Vectorized Operations:**\n",
        "1. Element-wise Operations:\n",
        "* Operations are automatically applied to each element of the array.\n",
        "* For example, adding two NumPy arrays together applies the addition element-wise:"
      ],
      "metadata": {
        "id": "Do04VViMwL9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "result = a + b"
      ],
      "metadata": {
        "id": "x6x7NefygpSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. No Explicit Loops:\n",
        "* Unlike traditional Python loops (for or while), vectorized operations avoid explicit iteration, leading to cleaner, more readable code and faster execution."
      ],
      "metadata": {
        "id": "D_l0Ez5Mgs5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = [x + y for x, y in zip(a, b)]\n",
        "result = a + b"
      ],
      "metadata": {
        "id": "IOfC27ybg567"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Performance:\n",
        "* Vectorized operations are significantly faster than their loop-based counterparts because they leverage NumPy’s underlying C implementation, which is optimized for performance.\n",
        "* Example of a large-scale computation:"
      ],
      "metadata": {
        "id": "TZ7Mcn5rg9Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(1000000)\n",
        "b = np.random.rand(1000000)\n",
        "result = a * b"
      ],
      "metadata": {
        "id": "EpMH7F31hD8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Memory Efficiency:\n",
        "* Vectorized operations are memory efficient because they avoid the overhead of Python loops and operate directly on arrays.\n",
        "\n",
        "5. Broadcasting:\n",
        "* NumPy’s vectorized operations support broadcasting, which allows operations on arrays of different shapes in a way that they are \"broadcast\" to a common shape."
      ],
      "metadata": {
        "id": "BgvaOTuzhHCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, 2, 3])\n",
        "b = np.array([10])\n",
        "result = a + b"
      ],
      "metadata": {
        "id": "76tOLsShhTql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benefits of Vectorized Operations:**\n",
        "* Speed: Operations are much faster than equivalent Python loops, especially for large datasets.\n",
        "* Readability: Code is more concise and easier to understand.\n",
        "* Convenience: Many mathematical and statistical functions are inherently vectorized, making it easier to perform complex operations.\n",
        "\n",
        "**Example Comparisons:**\n",
        "* Without Vectorization (using loops):"
      ],
      "metadata": {
        "id": "KpZUb3JJhXH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "result = np.zeros(3)\n",
        "for i in range(3):\n",
        "    result[i] = a[i] + b[i]"
      ],
      "metadata": {
        "id": "eDlf1bG8hlm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* With Vectorization:"
      ],
      "metadata": {
        "id": "IHcwGB--horl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = a + b"
      ],
      "metadata": {
        "id": "PuD6bAuYhsW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 9. How does Matplotlib differ from Plotly?\n",
        "**Ans** - Matplotlib and Plotly are both popular Python libraries for data visualization, but they serve different purposes and offer distinct features. Here's a detailed comparison of the two:\n",
        "\n",
        "1. **Interactivity:**\n",
        "* Matplotlib:\n",
        "  * Primarily designed for static, publication-quality plots.\n",
        "  * Basic interactivity (e.g., zooming, panning) is available in some interactive backends (like TkAgg or Qt5Agg), but the level of interactivity is limited compared to Plotly.\n",
        "  * Static plots are suitable for printed materials, reports, and academic papers.\n",
        "\n",
        "* Plotly:\n",
        "  * Built for creating interactive, web-based plots.\n",
        "  * Provides extensive interactivity out-of-the-box, including tooltips, hover effects, zooming, panning, and clickable legends.\n",
        "  * Ideal for dashboards, web applications, and any interactive data exploration.\n",
        "\n",
        "2. **Ease of Use and Learning Curve:**\n",
        "* Matplotlib:\n",
        "  *nHas a steeper learning curve due to its low-level control over plot elements.\n",
        "  * Requires more lines of code to create complex visualizations.\n",
        "  * Offers extensive customization options, which can be both a strength and a challenge for beginners.\n",
        "\n",
        "* Plotly:\n",
        "  * Higher-level API, making it easier to create complex visualizations with fewer lines of code.\n",
        "  * User-friendly, especially for interactive plots.\n",
        "  * Suitable for both beginners and experienced users looking for quick, interactive plots.\n",
        "\n",
        "3. **Customization:**\n",
        "* Matplotlib:\n",
        "  * Offers extensive customization options for every aspect of a plot, from colors and fonts to plot markers and annotations.\n",
        "  * Gives full control over the plot, making it highly flexible for tailored visualizations.\n",
        "\n",
        "* Plotly:\n",
        "  * Provides many customization options but with a focus on simplicity and ease of use.\n",
        "  * Customization is often achieved through high-level configuration rather than detailed manipulation of plot elements.\n",
        "\n",
        "4. **Output Formats:**\n",
        "* Matplotlib:\n",
        "  * Generates static plots that can be saved as images (PNG, JPG, SVG, PDF) and embedded in reports or presentations.\n",
        "  * Suitable for static content in print and academic publications.\n",
        "\n",
        "* Plotly:\n",
        "  * Creates interactive plots that are rendered in web browsers using HTML, JavaScript, and CSS.\n",
        "  * Plots can be embedded in web pages, Jupyter notebooks, and exported to HTML files for sharing.\n",
        "  * Supports exporting static images but is primarily geared towards interactive content.\n",
        "\n",
        "5. **Supported Plot Types:**\n",
        "* Matplotlib:\n",
        "  * Supports a wide range of plot types, including line plots, bar charts, scatter plots, histograms, and more.\n",
        "  * Good for creating custom, low-level plots that require detailed control over plot elements.\n",
        "\n",
        "* Plotly:\n",
        "  * Also supports a wide range of plot types, with an emphasis on interactivity.\n",
        "  * Includes more advanced plot types like 3D plots, contour plots, heatmaps, and even maps (geospatial plots).\n",
        "  * Suitable for creating complex, interactive visualizations with ease.\n",
        "\n",
        "6. **Integration:**\n",
        "* Matplotlib:\n",
        "  * Well-integrated with other scientific computing libraries like NumPy, SciPy, and Pandas.\n",
        "  * Frequently used in conjunction with Jupyter notebooks for data analysis.\n",
        "\n",
        "* Plotly:\n",
        "  * Also integrates well with Pandas and NumPy.\n",
        "  * Works seamlessly with Jupyter notebooks, providing inline interactive plots.\n",
        "  * Has native support for integration with Dash, a web application framework for building dashboards and interactive web apps.\n",
        "\n",
        "7. **Community and Support:**\n",
        "* Matplotlib:\n",
        "  * One of the oldest and most widely used Python plotting libraries, with extensive documentation and a large user community.\n",
        "  * Many tutorials, examples, and third-party resources are available.\n",
        "\n",
        "* Plotly:\n",
        "  * Growing user base with a strong focus on modern, interactive visualizations.\n",
        "  * Well-documented with many examples and tutorials, especially for interactive and web-based visualizations.\n",
        "\n",
        "**Table:**\n",
        "\n",
        "|Feature\t|Matplotlib\t|Plotly|\n",
        "|----|----|----|\n",
        "|Interactivity\t|Limited\t|Extensive built-in interactivity|\n",
        "|Learning Curve\t|Steeper\t|Easier, especially for interactivity|\n",
        "|Customization\t|Highly customizable\t|Simplified customization|\n",
        "|Output Formats\t|Static images\t|Interactive web-based plots|\n",
        "|Supported Plot Types\t|Extensive, traditional plots\t|Extensive, includes 3D and maps|\n",
        "|Integration\t|Strong with NumPy, Pandas, SciPy\t|Strong with Pandas, Jupyter, Dash|\n",
        "|Community Support\t|Large |well-established\tGrowing, modern focus|"
      ],
      "metadata": {
        "id": "rIRt7RPawSpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 10. What is the significance of hierarchical indexing in Pandas?\n",
        "**Ans** - Hierarchical indexing in Pandas is a powerful feature that allows us to work with data at multiple levels of granularity. It enables us to represent higher-dimensional data in a lower-dimensional DataFrame, facilitating complex data manipulations and analyses.\n",
        "\n",
        "**Significance of Hierarchical Indexing:**\n",
        "1. Handling Multi-Dimensional Data:\n",
        "* Hierarchical indexing allows the representation of multi-dimensional data in a 2-dimensional DataFrame or a 1-dimensional Series.\n",
        "* For example, a dataset with multiple categorical variables can be indexed hierarchically, making it easier to perform operations across different levels.\n",
        "2. Efficient Data Selection and Manipulation:\n",
        "* With hierarchical indexing, we can perform data selection, slicing, and manipulation more efficiently.\n",
        "* It supports selecting data at different levels of the hierarchy, allowing for complex queries."
      ],
      "metadata": {
        "id": "xMyKfqUzwUzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "arrays = [\n",
        "    ['Region1', 'Region1', 'Region2', 'Region2'],\n",
        "    ['2020', '2021', '2020', '2021']\n",
        "]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=('Region', 'Year'))\n",
        "df = pd.DataFrame({'Sales': [200, 250, 300, 400]}, index=index)\n",
        "print(df.loc['Region1'])"
      ],
      "metadata": {
        "id": "pdFMTojRkPte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Group By Operations:\n",
        "* Hierarchical indexing facilitates group-by operations on multiple levels, allowing for complex aggregations and transformations.\n",
        "* For example, we can group data by one level and perform aggregate calculations on another level.\n",
        "4. Enhanced Data Aggregation and Analysis:\n",
        "* Enables easy aggregation, transformation, and reshaping of data based on multiple keys.\n",
        "* We can aggregate data at any level of the index and perform sophisticated data analysis.\n",
        "5. Reshaping and Pivoting:\n",
        "* Hierarchical indexing supports reshaping operations like stack() and unstack(), which convert data between wide and long formats.\n",
        "* This is particularly useful for preparing data for visualization or further analysis."
      ],
      "metadata": {
        "id": "JWXwNSQ_kTyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unstacked = df.unstack('Year')"
      ],
      "metadata": {
        "id": "DB2-zo9dlfjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Concise Data Representation:\n",
        "* Allows for more concise data representation by collapsing multiple index levels into a single axis.\n",
        "* This makes it easier to visualize and manage complex datasets without the need for additional columns.\n",
        "\n",
        "7. Flexibility in Data Analysis:\n",
        "* We can easily switch between different levels of aggregation and granularity, providing flexibility in data exploration and analysis.\n",
        "\n",
        "**Example Use Cases:**\n",
        "* Time Series Data: Hierarchical indexing is often used in time series data where we might want to index data by both date and time.\n",
        "* Geographical Data: Indexing data by country, state, and city enables granular geographic analysis.\n",
        "* Multi-Category Sales Data: Indexing sales data by region, product type, and year allows for detailed sales analysis."
      ],
      "metadata": {
        "id": "Mpn9Xi4OlivY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 11. What is the role of Seaborn’s pairplot() function?\n",
        "**Ans** - The pairplot() function in Seaborn is a powerful tool for visualizing the pairwise relationships between multiple variables in a dataset. It creates a grid of scatter plots for each pair of variables in a DataFrame, along with histograms or density plots on the diagonal, offering an overview of how different variables relate to each other.\n",
        "\n",
        "**Roles and Features of pairplot():**\n",
        "1. Pairwise Relationship Visualization:\n",
        "* The primary role of pairplot() is to visualize the relationships between each pair of variables in a dataset. It generates scatter plots for each pair of columns to show their correlations and interactions.\n",
        "* This is especially useful when exploring a dataset with multiple continuous variables, allowing you to easily spot trends, clusters, or outliers.\n",
        "2. Diagonal Elements:\n",
        "* On the diagonal of the grid, the function typically shows univariate plots for each variable. This allows you to visualize the distribution of individual variables.\n",
        "* We can customize the type of plot on the diagonal (e.g., using a histogram or density plot).\n",
        "3. Customization of Aesthetics:\n",
        "* We can customize various aspects of the plot, such as:\n",
        "  * Color-coding points by a categorical variable.\n",
        "  * Adding regression lines or other elements.\n",
        "  * Adjusting the number of bins or the type of diagonal plot.\n",
        "4. Faceted Pairwise Plots:\n",
        "* The pairplot() function supports faceting by a categorical variable, allowing us to color the points based on the levels of that categorical variable. This is useful for exploring relationships between variables in different categories."
      ],
      "metadata": {
        "id": "8VxtZhKZx8hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "df = sns.load_dataset('iris')\n",
        "sns.pairplot(df, hue='species')"
      ],
      "metadata": {
        "id": "UEUznk3Amc2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Correlation Insights:\n",
        "* The scatter plots in the pair grid give insight into the correlation between pairs of variables. Strong positive or negative correlations can be easily spotted through the trends in the scatter plots, while weak or no correlation is reflected by more dispersed points.\n",
        "6. Outlier Detection:\n",
        "* Outliers can also be identified visually in the scatter plots. If data points are far from the general trend or cluster, they might be outliers.\n",
        "\n",
        "**Example of Usage:**"
      ],
      "metadata": {
        "id": "9Ixeoj8wmgs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "df = sns.load_dataset('iris')\n",
        "sns.pairplot(df, hue='species', markers=[\"o\", \"s\", \"D\"])"
      ],
      "metadata": {
        "id": "JPHH8GL4mw0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benefits of pairplot():**\n",
        "* Comprehensive Overview: It provides a quick, comprehensive overview of the relationships between variables in a dataset.\n",
        "* Univariate and Multivariate Exploration: It allows for both univariate (diagonal plots) and multivariate (off-diagonal scatter plots) exploration of data.\n",
        "* Quick Diagnostics: It's a useful diagnostic tool for identifying correlations, trends, and potential outliers."
      ],
      "metadata": {
        "id": "4KrLZkjEm0BH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 12. What is the purpose of the describe() function in Pandas?\n",
        "**Ans** - The describe() function in Pandas is used to generate descriptive statistics of a DataFrame or Series, providing a quick summary of the central tendencies, spread, and shape of the data. It is particularly useful for exploratory data analysis (EDA) to get a sense of the distribution and characteristics of numerical data.\n",
        "\n",
        "**Purpose of describe():**\n",
        "1. Summary Statistics:\n",
        "* The describe() function computes and returns various statistical measures for each numerical column in a DataFrame, such as:\n",
        "  * Count: The number of non-null entries in the column.\n",
        "  * Mean: The average of the values in the column.\n",
        "  * Standard Deviation (std): The spread or variability of the values.\n",
        "  * Minimum (min): The smallest value in the column.\n",
        "  * 25th Percentile (25%): The value below which 25% of the data falls (first quartile).\n",
        "  * 50th Percentile (50%): The median value (second quartile).\n",
        "  * 75th Percentile (75%): The value below which 75% of the data falls (third quartile).\n",
        "  * Maximum (max): The largest value in the column.\n",
        "\n",
        "For categorical columns, describe() provides:\n",
        "* Count: The number of non-null entries.\n",
        "* Unique: The number of unique categories.\n",
        "* Top: The most frequent category.\n",
        "* Freq: The frequency of the most common category.\n",
        "\n",
        "2. Quick Overview of Data:\n",
        "* describe() provides a high-level summary of the dataset’s numerical or categorical characteristics, which is very helpful in the initial stages of data analysis to understand the distribution and identify potential issues (such as outliers or skewed data).\n",
        "3. Data Exploration:\n",
        "* By using describe(), you can quickly assess:\n",
        "  * The central tendency (mean, median).\n",
        "  * The spread or variation (standard deviation, interquartile range).\n",
        "  * Potential outliers (based on min/max values).\n",
        "  * Skewness in the data (e.g., comparing the mean and median).\n",
        "4. Handling Missing Data:\n",
        "* It shows the count of non-null entries in each column, which helps identify columns with missing data. This can guide data cleaning efforts.\n",
        "\n",
        "**Example:**"
      ],
      "metadata": {
        "id": "V-4hlZSbx_nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Age': [23, 45, 12, 36, 56, 23, 45],\n",
        "    'Height': [5.6, 5.8, 5.5, 5.9, 6.0, 5.7, 5.8],\n",
        "    'Salary': [50000, 60000, 35000, 80000, 75000, 52000, 62000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "QF3mOM1En_ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customization:**\n",
        "* You can customize the describe() function with parameters to control the output:\n",
        "  * include: Specify which data types to include in the summary (e.g., 'all' for all columns, 'object' for categorical data, 'number' for numerical data).\n",
        "  * percentiles: You can define specific percentiles to include in the output, in addition to the default 25%, 50%, and 75%."
      ],
      "metadata": {
        "id": "iRP6SThFoEMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 13. Why is handling missing data important in Pandas?\n",
        "**Ans** - Handling missing data is a critical step in data preprocessing, especially when working with real-world datasets. Incomplete data can lead to biased analyses, inaccurate models, and incorrect conclusions. Pandas provides various tools and methods to identify, manage, and clean missing data, ensuring that the dataset is in the best possible shape for analysis.\n",
        "\n",
        "**Importance of Handling Missing Data in Pandas:**\n",
        "1. Ensures Accurate Analysis:\n",
        "* Impact on Calculations: Missing data can skew statistical calculations such as mean, median, standard deviation, and other aggregations. If not handled properly, these calculations can be misleading and affect the integrity of our analysis.\n",
        "* Bias in Models: Many machine learning algorithms rely on complete datasets for training. Missing data can cause biased model predictions, as the model may ignore or misinterpret missing values, leading to incorrect results.\n",
        "2. Prevents Data Loss:\n",
        "* If missing data is not handled properly, valuable information may be lost. Instead of removing rows or columns that contain missing values, it's often better to impute missing data or use other strategies to retain as much useful information as possible.\n",
        "3. Improves Model Performance:\n",
        "* Some machine learning algorithms can handle missing data better than others, but many algorithms do not work well with missing values.\n",
        "* Properly handling missing data can lead to better model performance and more accurate predictions.\n",
        "4. Helps in Data Cleaning and Transformation:\n",
        "* Missing data is often an indicator of problems in data collection or data entry. Identifying and handling missing values early in the data cleaning process can help in understanding the nature of the missingness, whether it's random or systematic, and whether certain data entries require special attention.\n",
        "5. Preserves Data Integrity:\n",
        "* Proper handling of missing data ensures the integrity and quality of the dataset, which is essential for any downstream analysis or modeling task.\n",
        "* It also helps prevent errors that could arise during data manipulation and processing."
      ],
      "metadata": {
        "id": "_Feh4Pr5yBkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 14. What are the benefits of using Plotly for data visualization?\n",
        "**Ans** - Plotly is a popular data visualization library in Python that provides a wide range of benefits for creating interactive, visually appealing, and highly customizable charts and plots. It is widely used for both static and interactive visualizations, making it a versatile tool for data analysis and presentation.\n",
        "\n",
        "**benefits of using Plotly for data visualization:**\n",
        "1. **Interactive Visualizations:**\n",
        "* Plotly is known for its interactive capabilities. Unlike static plots, Plotly plots allow users to interact with the visualization in real-time, such as zooming, panning, hovering for data points, and dynamically filtering data.\n",
        "* This interactivity makes it easier to explore large datasets and uncover patterns or insights that may not be immediately apparent in static visualizations.\n",
        "\n",
        "Example: In a scatter plot, you can hover over points to see exact values, zoom in to focus on a specific region, or toggle different series on and off.\n",
        "\n",
        "2. **High-Quality and Aesthetic Plots:**\n",
        "* Plotly produces visually appealing, publication-quality charts that are aesthetically rich and clean by default. It offers a variety of themes, colors, and styles, ensuring that the visualizations are both informative and attractive.\n",
        "* The plots can be customized with ease to match the needs of a project or presentation.\n",
        "\n",
        "3. **Wide Range of Plot Types:**\n",
        "* Plotly supports a diverse set of chart types, including basic charts, statistical plots, geographical maps, and more advanced charts.\n",
        "* This wide variety of available plots makes Plotly highly adaptable to various types of data and analysis.\n",
        "\n",
        "4. **Web-Based and Embeddable Visualizations:**\n",
        "* Plotly visualizations are web-based, meaning they can be easily embedded in websites or shared via links. They can be published on platforms such as Plotly Dash, Jupyter notebooks, or even as standalone HTML files.\n",
        "* This makes it ideal for sharing visualizations online, in reports, or in interactive dashboards, allowing a wider audience to access and interact with the visualizations.\n",
        "\n",
        "5. **Integration with Dash for Interactive Dashboards:**\n",
        "* Dash, which is built on top of Plotly, allows for the creation of interactive web-based dashboards. Dash is a powerful framework that allows you to combine Plotly visualizations with user input controls, such as dropdowns, sliders, and buttons, to create fully interactive data applications.\n",
        "* This is particularly beneficial for building real-time data dashboards for business intelligence, data monitoring, or any application requiring dynamic visualization.\n",
        "\n",
        "6. **Customizability and Flexibility:**\n",
        "* Plotly offers a high degree of customizability. You can modify every aspect of our visualizations, such as axes, grid lines, legends, colors, fonts, and annotations.\n",
        "* It also provides full access to the underlying plot data and rendering objects, allowing you to adjust plots programmatically and create sophisticated visualizations tailored to our specific requirements.\n",
        "\n",
        "7. **Seamless Integration with Pandas and NumPy:**\n",
        "* Plotly works well with Pandas and NumPy, which makes it easy to integrate with datasets stored in DataFrames or arrays. we can directly pass Pandas DataFrames or Series into Plotly functions to generate charts.\n",
        "* This integration streamlines the process of creating visualizations from data without needing to manually preprocess the data.\n",
        "\n",
        "8. **Real-Time and Streaming Data Visualization:**\n",
        "* Plotly supports streaming data, which allows real-time visualizations. we can create plots that update dynamically as new data is received, making it a great tool for monitoring and visualizing real-time data, such as sensor readings, live stock prices, or IoT data.\n",
        "\n",
        "9. **Support for 3D and Geospatial Plots:**\n",
        "* Plotly provides built-in support for 3D visualizations, which can be useful for visualizing complex, high-dimensional data in a more intuitive way.\n",
        "* It also supports geospatial plots, such as maps, allowing you to create choropleth maps, scatter plots over maps, or geographical heatmaps. This is particularly useful for visualizing location-based data.\n",
        "\n",
        "10. **Easy Exporting and Sharing:**\n",
        "* Plotly visualizations can be easily exported as interactive HTML files, PNG, JPEG, or PDF files for use in reports and presentations.\n",
        "* The interactive nature of the plots is preserved when exporting to HTML, so others can interact with the plot without needing to run code."
      ],
      "metadata": {
        "id": "yx9---v5yKbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 15.How does NumPy handle multidimensional arrays?\n",
        "**Ans** - NumPy handles multidimensional arrays through the ndarray object, which is a flexible and efficient structure for storing and manipulating arrays with multiple dimensions. These multidimensional arrays can represent anything from a 2D matrix to higher-dimensional data structures.\n",
        "\n",
        "**Features of NumPy Multidimensional Arrays:**\n",
        "1. Shape and Dimensions (ndarray.shape and ndarray.ndim):\n",
        "* Every NumPy array has a shape, which is a tuple that describes the size of the array along each dimension. For example, a 2D array with 3 rows and 4 columns would have a shape of (3, 4).\n",
        "* The ndim attribute tells you the number of dimensions in the array.\n",
        "  * For example:"
      ],
      "metadata": {
        "id": "vnhbT1_gyNUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(arr_2d.shape)\n",
        "print(arr_2d.ndim)\n",
        "arr_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(arr_3d.shape)\n",
        "print(arr_3d.ndim)"
      ],
      "metadata": {
        "id": "XtoiSz_C_Cjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Indexing and Slicing:\n",
        "* NumPy supports advanced indexing and slicing for multidimensional arrays, which makes it easy to access and modify specific elements, rows, columns, or subarrays.\n",
        "* You can use comma-separated indices to access elements across different dimensions.\n",
        "\n",
        "Example (2D Array Indexing):"
      ],
      "metadata": {
        "id": "8A3ulUSy_HP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(arr_2d[0, 2])\n",
        "print(arr_2d[1, :])\n",
        "print(arr_2d[:, 1])"
      ],
      "metadata": {
        "id": "ggr1bKBI_Xja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example (3D Array Indexing):"
      ],
      "metadata": {
        "id": "X6A4FT57_cVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(arr_3d[1, 0, 1])\n",
        "print(arr_3d[1, :, :])"
      ],
      "metadata": {
        "id": "CQO8AB56_lib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Broadcasting:\n",
        "* Broadcasting is a powerful feature in NumPy that allows operations on arrays of different shapes. When performing operations between arrays of different shapes, NumPy automatically adjusts (or \"broadcasts\") the smaller array to match the shape of the larger array.\n",
        "* This helps to perform element-wise operations across multidimensional arrays without the need for explicit loops.\n",
        "\n",
        "Example (Broadcasting):"
      ],
      "metadata": {
        "id": "WAkXTMCO_qKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_2d = np.array([[1, 2], [3, 4]])\n",
        "arr_1d = np.array([10, 20])\n",
        "result = arr_2d + arr_1d\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6kvHfNaR_1lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the 1D array [10, 20] is \"broadcast\" over each row of the 2D array, and the addition operation is performed element-wise.\n",
        "\n",
        "4. Reshaping Multidimensional Arrays:\n",
        "* You can reshape multidimensional arrays into different shapes using the reshape() function, as long as the total number of elements remains the same. This allows for convenient manipulation of the array's structure without changing its data.\n",
        "\n",
        "Example (Reshaping):"
      ],
      "metadata": {
        "id": "sEp1ve-W_8-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "reshaped = arr.reshape(3, 4)\n",
        "print(reshaped)"
      ],
      "metadata": {
        "id": "vnDriFvWAJg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Advanced Operations on Multidimensional Arrays:\n",
        "* NumPy provides a variety of mathematical and statistical functions that work seamlessly across multidimensional arrays. For example:\n",
        "  * Sum across axes: You can compute the sum of elements along a particular axis (row or column)."
      ],
      "metadata": {
        "id": "X7Eac0tcAM0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(np.sum(arr_2d, axis=1))\n",
        "print(np.sum(arr_2d, axis=0))"
      ],
      "metadata": {
        "id": "4uOeHo5NAXka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Matrix multiplication: You can perform matrix operations such as dot products, matrix multiplication, and element-wise operations."
      ],
      "metadata": {
        "id": "S1x5zYe9Abh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = np.array([[1, 2], [3, 4]])\n",
        "arr2 = np.array([[5, 6], [7, 8]])\n",
        "product = np.dot(arr1, arr2)\n",
        "print(product)"
      ],
      "metadata": {
        "id": "70AmwBodAiNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Flattening Multidimensional Arrays:\n",
        "* You can flatten a multidimensional array into a 1D array using flatten() or ravel(). This is useful when you need to apply functions that expect a 1D input or when you want to reduce the dimensionality of the array.\n",
        "\n",
        "Example (Flattening):"
      ],
      "metadata": {
        "id": "1tzbAQreAlm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_2d = np.array([[1, 2], [3, 4]])\n",
        "flattened = arr_2d.flatten()\n",
        "print(flattened)"
      ],
      "metadata": {
        "id": "ZvCL79tLAwT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of Multidimensional Array (3D):"
      ],
      "metadata": {
        "id": "ap_gRo54A1h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr_3d = np.array([[[1, 2], [3, 4], [5, 6]],\n",
        "                   [[7, 8], [9, 10], [11, 12]]])\n",
        "print(arr_3d[0, 1, 1])\n",
        "print(arr_3d[1, :, :])\n",
        "reshaped = arr_3d.reshape(6, 2)\n",
        "print(reshaped)"
      ],
      "metadata": {
        "id": "zDyMUBoWA66C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 16. What is the role of Bokeh in data visualization?\n",
        "**Ans** - Bokeh is a powerful and interactive data visualization library in Python that enables the creation of visually appealing and interactive plots, dashboards, and applications. It is particularly well-suited for creating web-based visualizations that can be embedded in web applications or shared online. Bokeh is designed to produce interactive plots with relatively simple code and is highly customizable to meet the needs of different types of visualizations.\n",
        "\n",
        "**Roles and Features of Bokeh in Data Visualization:**\n",
        "1. Interactive Visualizations:\n",
        "* One of the most significant strengths of Bokeh is its ability to create interactive plots by default. These visualizations can include features such as hover tools, zooming, panning, and clicking. This makes it easy to explore data in an intuitive and dynamic way.\n",
        "* Users can interact with data directly within the visualization, which can help uncover patterns and trends that may not be as apparent in static plots.\n",
        "\n",
        "2. Web-Based and Embeddable Visualizations:\n",
        "* Bokeh visualizations are rendered as HTML and JavaScript files, meaning they can be easily embedded into web pages, reports, or applications.\n",
        "* This makes it an excellent choice for building interactive dashboards and data applications that can be accessed through a browser.\n",
        "* Bokeh plots can also be shared as standalone HTML files, making them easy to distribute or publish without needing a server.\n",
        "\n",
        "3. **Versatility and Wide Range of Plot Types:**\n",
        "* Bokeh supports a wide variety of plot types, including:\n",
        "  * Basic plots: Line, scatter, bar, histogram, etc.\n",
        "  * Geospatial visualizations: Geographical plots like choropleth maps and scatter plots over maps.\n",
        "  * 3D plots: Bokeh supports 3D plotting capabilities for visualizing multi-dimensional data.\n",
        "  * Network graphs: Visualizing relationships between entities using node-link diagrams.\n",
        "  * Statistical plots: Box plots, violin plots, heatmaps, etc.\n",
        "\n",
        "4. **Customization and Flexibility:**\n",
        "* Bokeh provides extensive customization options. You can control every aspect of the plot, including colors, axes, grid lines, legends, tooltips, and more. It also allows you to create custom interactivity using its high-level interface.\n",
        "* The Bokeh server allows for even greater flexibility by enabling you to create interactive applications that respond to user input in real-time.\n",
        "\n",
        "5. Integration with Other Python Libraries:\n",
        "* Bokeh works well with Pandas and NumPy, and it can be used to visualize data stored in DataFrames or arrays directly. You can pass Pandas DataFrames or NumPy arrays to Bokeh to create plots seamlessly.\n",
        "* It also integrates with Jupyter notebooks, allowing you to visualize data interactively within a notebook environment.\n",
        "\n",
        "6. Real-Time Data Streaming:\n",
        "* Bokeh supports real-time data updates, making it ideal for visualizing streaming data. This can be particularly useful for applications like monitoring systems, financial data, sensor readings, and other dynamic datasets where the plot needs to update as new data becomes available.\n",
        "\n",
        "7. High-Performance for Large Datasets:\n",
        "* Bokeh is optimized for handling large datasets efficiently. While libraries like Matplotlib or Seaborn are typically used for smaller datasets, Bokeh can scale well for larger datasets and still maintain interactivity and smooth performance.\n",
        "\n",
        "8. Easy Integration with Web Frameworks:\n",
        "* Bokeh can be easily integrated into web frameworks like Flask or Django. This makes it a great choice for building custom web applications with interactive data visualizations.\n",
        "\n",
        "9. Standalone and Interactive Web Applications:\n",
        "* Bokeh enables the creation of interactive web applications through its Bokeh server. The Bokeh server allows you to build applications that can interact with both the frontend and backend, and update visualizations in response to user actions or changes in underlying data.\n",
        "* This can be used to build dashboards, monitoring systems, or other custom data applications that require real-time interactivity.\n",
        "\n",
        "Example Code for Bokeh:"
      ],
      "metadata": {
        "id": "VpQQkjmxyPSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import HoverTool\n",
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'x': [1, 2, 3, 4, 5],\n",
        "    'y': [10, 20, 30, 40, 50],\n",
        "    'size': [10, 20, 30, 40, 50],\n",
        "    'color': ['red', 'blue', 'green', 'yellow', 'orange']\n",
        "})\n",
        "p = figure(title=\"Basic Scatter Plot\", x_axis_label=\"X-Axis\", y_axis_label=\"Y-Axis\")\n",
        "hover = HoverTool()\n",
        "hover.tooltips = [(\"X\", \"@x\"), (\"Y\", \"@y\"), (\"Size\", \"@size\"), (\"Color\", \"@color\")]\n",
        "p.add_tools(hover)\n",
        "p.circle('x', 'y', size='size', color='color', source=data, alpha=0.6)\n",
        "show(p)"
      ],
      "metadata": {
        "id": "kLp2lwyKCXby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of Bokeh:**\n",
        "* Interactivity: Built-in interactivity (zooming, panning, hover) makes exploring data easier.\n",
        "* Web-Ready: Ideal for creating visualizations that are embedded or shared on the web.\n",
        "* Customization: Highly customizable for creating tailored visualizations.\n",
        "* Scalability: Handles large datasets and real-time data efficiently.\n",
        "* Integration with Python Libraries: Works seamlessly with Pandas, NumPy, and other Python data libraries.\n",
        "* Real-Time Data: Suitable for visualizing streaming or real-time data."
      ],
      "metadata": {
        "id": "Qg6_L8upCdpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 17. Explain the difference between apply() and map() in Pandas?\n",
        "**Ans** - In Pandas, both apply() and map() are used to apply a function to a DataFrame or Series, but they differ in terms of their functionality, flexibility, and how they handle data structures.\n",
        "\n",
        "1. **Apply()**\n",
        "* The apply() function is used to apply a function along a specific axis (either rows or columns) of a DataFrame, or to the entire Series.\n",
        "* apply() can be used on both Series and DataFrames, and it allows for greater flexibility in how the function is applied.\n",
        "* When used on a Series, it applies a function to each element of the Series.\n",
        "* When used on a DataFrame, it applies the function to each column or row depending on the axis specified.\n",
        "\n",
        "Key Points:\n",
        "* Can be applied to both Series and DataFrames.\n",
        "* More flexible and allows you to work with entire rows or columns (if used with a DataFrame).\n",
        "* axis=0 (default) means the function is applied to each column.\n",
        "* axis=1 means the function is applied to each row.\n",
        "\n",
        "Example: apply() with Series"
      ],
      "metadata": {
        "id": "Ct-GELg0yR8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "s = pd.Series([1, 2, 3, 4, 5])\n",
        "result = s.apply(lambda x: x**2)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "HX5KmV0XDGfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: apply() with DataFrame"
      ],
      "metadata": {
        "id": "FI0Nkw1_DLxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [4, 5, 6]\n",
        "})\n",
        "result = df.apply(lambda x: x.sum())\n",
        "print(result)\n",
        "result = df.apply(lambda x: x.mean(), axis=1)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YOhZarxZDT0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **map()**\n",
        "* The map() function is used to apply a function to each element in a Series (not a DataFrame).\n",
        "* map() is typically used for element-wise transformations and is more limited in scope compared to apply().\n",
        "* It works with Series only, and the function is applied element-wise.\n",
        "* We can pass a dictionary, Series, or function to map() to replace or transform values.\n",
        "\n",
        "Key Points:\n",
        "* Can only be used with a Series.\n",
        "* Typically used for element-wise transformations or for mapping existing values to new ones.\n",
        "* Can map values from a dictionary or a Series.\n",
        "\n",
        "Example: map() with a function"
      ],
      "metadata": {
        "id": "a8Dib-xcDZmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series([1, 2, 3, 4, 5])\n",
        "result = s.map(lambda x: x * 10)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "87cr6VA9DpmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: map() with a dictionary (value replacement)"
      ],
      "metadata": {
        "id": "rUGNkNW5DuSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series(['cat', 'dog', 'rabbit', 'dog'])\n",
        "map_dict = {'cat': 'kitten', 'dog': 'puppy'}\n",
        "result = s.map(map_dict)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "LJwRcng_DtHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Differences Between apply() and map()**\n",
        "\n",
        "|Feature\t|apply()\t|map()|\n",
        "|----|----|----|\n",
        "|Usage\t|Can be used with both Series and DataFrames.\t|Used only with Series.|\n",
        "|Function\t|Can apply any function.\t|Applies a function element-wise.|\n",
        "|Flexibility\t|More flexible; can apply functions to entire rows or columns.\t|Less flexible; typically used for element-wise operations.|\n",
        "|Input Type\t|Accepts a function or a callable that operates on rows/columns of DataFrame or elements of Series.\t|Accepts a function, dictionary, or Series.|\n",
        "|Output\t|Can return a modified Series or DataFrame.\t|Returns a new Series with transformed elements.|\n",
        "|Speed\t|Generally slower than map() for element-wise operations.\t|Faster for simple element-wise operations on Series.|\n",
        "\n",
        "**Use of apply() vs map()**:\n",
        "* Use apply() when:\n",
        "  * We need to apply a function across rows or columns in a DataFrame.\n",
        "  * We are working with complex operations that involve rows or columns of data (e.g., aggregations, transformations).\n",
        "  * We need to apply a function that works on entire rows or columns, not just element-wise operations.\n",
        "* Use map() when:\n",
        "  * We are working with a Series and need to apply a simple, element-wise function.\n",
        "  * We want to map values from one set of values to another using a dictionary or Series.\n",
        "  * We are performing simple transformations on individual elements of a Series."
      ],
      "metadata": {
        "id": "cVepZIE_D2zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 18. What are some advanced features of NumPy?\n",
        "**Ans** - NumPy is a powerful library for numerical computing in Python. It offers many advanced features that make it highly efficient for performing operations on large datasets. These advanced features allow users to perform complex mathematical operations with ease and flexibility.\n",
        "\n",
        "Advanced features of NumPy:\n",
        "1. **Broadcasting**\n",
        "* Broadcasting allows NumPy to perform element-wise operations on arrays of different shapes and sizes without the need for explicit looping. The smaller array is \"broadcast\" over the larger array to make their shapes compatible.\n",
        "* This feature reduces memory usage and improves performance, as operations are performed without duplicating data.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "nl34C3qgyVM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([10, 20])\n",
        "result = A + B\n",
        "print(result)"
      ],
      "metadata": {
        "id": "lFCkkWnpEp4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Advanced Indexing and Slicing**\n",
        "* NumPy allows complex and advanced indexing techniques such as boolean indexing, fancy indexing, and slicing with multiple dimensions.\n",
        "* Fancy indexing allows us to index arrays with other arrays, making it possible to access multiple elements at once.\n",
        "* Boolean indexing allows us to select elements that satisfy certain conditions.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "W1mItK7YEum2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(arr[[0, 2, 4]])\n",
        "print(arr[arr > 2])"
      ],
      "metadata": {
        "id": "uD3n6HHgE8Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Vectorized Operations**\n",
        "* NumPy supports vectorized operations, meaning we can perform operations on entire arrays without using explicit loops.\n",
        "* This leads to more concise and faster code, as operations are applied element-wise on the entire array using optimized C code under the hood.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "yTLH8k3SFBQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4])\n",
        "result = arr * 2\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f5A48ozaFMwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Linear Algebra**\n",
        "* NumPy provides a wide range of functions for performing linear algebra operations, such as matrix multiplication, eigenvalue decomposition, solving linear systems, and more.\n",
        "* These operations are available in the numpy.linalg module.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "fVNSpE_6FQPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "result = np.dot(A, B)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "udGocMHEFbHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Random Sampling and Distribution**\n",
        "* NumPy has a robust set of functions in the numpy.random module for generating random numbers, sampling from probability distributions, and shuffling data.\n",
        "* This includes sampling from normal distributions, binomial distributions, and uniform distributions, among others.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "6BMdbdLcFgHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_arr = np.random.rand(2, 3)\n",
        "print(rand_arr)\n",
        "normal_arr = np.random.normal(loc=0, scale=1, size=5)\n",
        "print(normal_arr)"
      ],
      "metadata": {
        "id": "DIjQbLbgFr89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Fast Fourier Transform (FFT)**\n",
        "* NumPy provides the numpy.fft module for efficient computation of the Fast Fourier Transform (FFT), which is used for analyzing the frequency components of a signal or time series data.\n",
        "* This is commonly used in signal processing, image processing, and time-series analysis.\n",
        "\n",
        "Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "E3iz8Bq9FwD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3, 4])\n",
        "fft_result = np.fft.fft(x)\n",
        "print(fft_result)"
      ],
      "metadata": {
        "id": "pvTxKmq7GeBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Polynomials**\n",
        "* The numpy.poly module provides support for polynomial operations, including polynomial fitting, evaluation, and manipulation.\n",
        "* We can create and evaluate polynomials, find their roots, and perform operations like polynomial addition and multiplication.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "B0Oiuo5nGhWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.poly1d([1, -3, 2])\n",
        "print(p(3))\n",
        "roots = np.roots(p)\n",
        "print(roots)"
      ],
      "metadata": {
        "id": "aT7Y7yGeGmDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Memory Management (Views and Copies)**\n",
        "* NumPy provides mechanisms for handling memory efficiently through views and copies.\n",
        "* Views refer to arrays that share the same memory, while copies create new arrays with independent memory allocations.\n",
        "* Understanding when NumPy creates views versus copies can help reduce memory usage and speed up computations.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "xd4gOgsQGqSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "arr_view = arr[1:4]\n",
        "arr_copy = arr[1:4].copy()"
      ],
      "metadata": {
        "id": "p8UdcqNvGvcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **Structured Arrays and Record Arrays**\n",
        "* Structured arrays allow you to store heterogeneous data types in a single array. This is similar to rows in a table or database.\n",
        "* Record arrays are a variant of structured arrays that provide attribute-style access to fields.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "-vW1iBpyGytX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = np.dtype([('name', 'S10'), ('age', 'i4')])\n",
        "arr = np.array([('Alice', 25), ('Bob', 30)], dtype=dt)\n",
        "print(arr['name'])"
      ],
      "metadata": {
        "id": "FahT_ViBG3U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **Memory-Mapped Files**\n",
        "* Memory-mapped files allow us to read large arrays from disk as if they were in memory, enabling us to work with datasets that are too large to fit into RAM.\n",
        "* The numpy.memmap function allows us to map a file directly into memory and treat it as a NumPy array, with the advantage of only loading the necessary data when needed.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "8fC12hKOG7Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mmap_arr = np.memmap('large_data.dat', dtype='float32', mode='r', shape=(100000, 100))\n",
        "print(mmap_arr.shape)"
      ],
      "metadata": {
        "id": "NaSI8rpTG-Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. **Optimization with np.vectorize()**\n",
        "* np.vectorize() is a convenience function that allows us to apply a Python function element-wise to a NumPy array without needing to explicitly write loops. It’s essentially a wrapper around Python loops that makes code more readable.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "rIYM47ChHBWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_func(x):\n",
        "    return x ** 2\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "vectorized_func = np.vectorize(my_func)\n",
        "result = vectorized_func(arr)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4hWGf4ckHEyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. **Advanced Statistical Functions**\n",
        "* NumPy provides a range of advanced statistical functions in numpy.random and numpy.stats for calculating distributions, generating random variables, and conducting statistical analysis.\n",
        "* Functions like covariance, correlation, percentiles, histograms, and more are available.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "Cr34_gwrHHg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = np.array([1, 2, 3])\n",
        "arr2 = np.array([4, 5, 6])\n",
        "covariance_matrix = np.cov(arr1, arr2)\n",
        "print(covariance_matrix)"
      ],
      "metadata": {
        "id": "rhMWAWc3HLWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 19. How does Pandas simplify time series analysis?\n",
        "**Ans** - Pandas simplifies time series analysis by providing a powerful set of tools and functions specifically designed for handling time-based data. Time series analysis involves analyzing data points collected or recorded at specific time intervals, and Pandas makes it easier to work with such data by offering various features for manipulating, indexing, and visualizing time series data.\n",
        "\n",
        "some ways in which Pandas simplifies time series analysis:\n",
        "\n",
        "1. **Datetime Indexing and Parsing**\n",
        "* DatetimeIndex: Pandas has a specialized DatetimeIndex for handling time series data. we can set a column with timestamps as the index of a DataFrame, making it easier to perform time-based operations.\n",
        "* Datetime conversion: Pandas can easily convert date strings into datetime objects, enabling more convenient manipulation of time-based data.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "OJ9S_7cYyXOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dates = pd.to_datetime(['2025-01-01', '2025-02-01', '2025-03-01'])\n",
        "print(dates)"
      ],
      "metadata": {
        "id": "f8Qu6WJWHkZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Resampling**\n",
        "* Resampling allows us to change the frequency of time series data, which is essential for downsampling or upsampling. For example, we can convert daily data to monthly data, or vice versa.\n",
        "* Pandas provides the resample() method, which allows us to specify a frequency (e.g., 'D' for daily, 'M' for monthly) and aggregate the data using functions like mean, sum, etc.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "CPyDJXxvHzAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, 2, 3, 4, 5], index=pd.date_range('2025-01-01', periods=5, freq='D'))\n",
        "resampled_data = data.resample('2D').sum()\n",
        "print(resampled_data)"
      ],
      "metadata": {
        "id": "79GsURCiIAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Time-Based Indexing**\n",
        "* Pandas allows us to index DataFrames by time, making it easy to filter or select data within specific time periods. We can use string slicing or pd.Timestamp objects for time-based indexing.\n",
        "* We can use .loc[] or .iloc[] to access specific time intervals.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "o0JDVSJ7IPc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([10, 20, 30, 40, 50], index=pd.date_range('2025-01-01', periods=5, freq='D'))\n",
        "print(data['2025-01-02':'2025-01-04'])"
      ],
      "metadata": {
        "id": "29Ri8mNdIaLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Time Shifting**\n",
        "* Shifting allows us to shift time series data forward or backward by a specified time period. This is useful for calculating differences, lagging, and other time-related operations.\n",
        "* The shift() function shifts the data by a specified number of periods, and tshift() allows shifting the time index.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "MOqQy4LXImJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, 2, 3, 4], index=pd.date_range('2025-01-01', periods=4, freq='D'))\n",
        "shifted_data = data.shift(1)\n",
        "print(shifted_data)"
      ],
      "metadata": {
        "id": "i_fgmDHbIuUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Date Offsets and Frequency Handling**\n",
        "* Pandas supports date offsets that make it easy to manipulate time frequencies. We can perform operations such as adding months, subtracting days, or working with business days.\n",
        "* pd.DateOffset allows us to create custom date offsets, while pd.tseries.offsets provides specialized options like MonthEnd, BMonthBegin, etc.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "GLFzrwpzI4rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date = pd.Timestamp('2025-01-01')\n",
        "new_date = date + pd.DateOffset(months=2)\n",
        "print(new_date)"
      ],
      "metadata": {
        "id": "NlFJCvAnJBXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Time Zone Handling**\n",
        "* Pandas provides robust support for time zones, allowing us to convert between time zones, localize times, and handle daylight saving time (DST).\n",
        "* We can use .tz_localize() to assign a time zone to a timestamp, and .tz_convert() to convert it to another time zone.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "nDolLrKcJEwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, 2, 3], index=pd.date_range('2025-01-01', periods=3, freq='D'))\n",
        "data_utc = data.tz_localize('UTC')\n",
        "data_pacific = data_utc.tz_convert('US/Pacific')\n",
        "print(data_pacific)"
      ],
      "metadata": {
        "id": "F1NqdUixJLQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Rolling Windows and Moving Averages**\n",
        "* Rolling windows are useful for calculating statistics such as moving averages or rolling sums over time. Pandas provides the rolling() function, which allows us to apply a window function to time series data.\n",
        "* Rolling operations are helpful for smoothing out fluctuations or analyzing trends over time.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "B2SX5n1wJOxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('2025-01-01', periods=6, freq='D'))\n",
        "rolling_mean = data.rolling(window=3).mean()\n",
        "print(rolling_mean)"
      ],
      "metadata": {
        "id": "xWzGs1-RJXIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Handling Missing Data in Time Series**\n",
        "* Time series data often contains missing values, which can occur due to irregular sampling or other reasons. Pandas provides methods such as fillna(), interpolate(), and dropna() to handle missing data in time series.\n",
        "* We can fill missing values using forward fill, backward fill, or interpolation techniques.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "mG78r_TsJ29l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, np.nan, 3, np.nan, 5], index=pd.date_range('2025-01-01', periods=5, freq='D'))\n",
        "filled_data = data.fillna(method='ffill')\n",
        "print(filled_data)"
      ],
      "metadata": {
        "id": "VT7NQxiyJ8NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **Period and Frequency Conversion**\n",
        "* Pandas allows us to convert between different frequencies of time-based data using PeriodIndex and TimedeltaIndex.\n",
        "* We can convert daily data to monthly or yearly data, or vice versa, using .asfreq() and other related functions.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "u0pY76iFJ_hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([10, 20, 30], index=pd.date_range('2025-01-01', periods=3, freq='D'))\n",
        "monthly_data = data.asfreq('M')\n",
        "print(monthly_data)"
      ],
      "metadata": {
        "id": "tTl6UP9FKERk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **Visualization of Time Series**\n",
        "* Pandas integrates well with Matplotlib, making it easy to visualize time series data. We can directly plot time series using .plot() on a Pandas DataFrame or Series, and time-related plots (like line plots, bar plots, etc.) are automatically formatted with appropriate time-based x-axes.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "3JCCyXG0KHj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([1, 2, 3, 4], index=pd.date_range('2025-01-01', periods=4, freq='D'))\n",
        "data.plot(title=\"Time Series Plot\")"
      ],
      "metadata": {
        "id": "7Cw0yxX_KLEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 20. What is the role of a pivot table in Pandas?\n",
        "**Ans** - A pivot table in Pandas is a powerful tool used to summarize and aggregate data in a DataFrame, transforming long-form data into a more organized, table-like structure. Pivot tables allow you to reorganize and compute statistics based on specific grouping variables. This is especially useful for data analysis and exploration, as it lets you extract key insights from large datasets by breaking them down into meaningful summaries.\n",
        "\n",
        "**Roles of Pivot Tables in Pandas:**\n",
        "1. Data Summarization: Pivot tables allow us to summarize large datasets by calculating aggregated statistics such as mean, sum, count, or other functions for groups of data. This is very useful for spotting trends, patterns, and anomalies.\n",
        "\n",
        "2. Data Reshaping: Pivot tables can help reshape data by converting long-form data into a wider format, with distinct values of a column appearing as column headers. This allows for easier comparison of different groups across multiple variables.\n",
        "\n",
        "3. Grouping and Aggregation: We can group data by one or more columns and apply aggregation functions to calculate statistical values for each group. This helps in performing operations like summing, averaging, or counting values within each group.\n",
        "\n",
        "4. Multi-Level Pivoting: Pivot tables can be multi-dimensional, meaning we can pivot on multiple columns, resulting in a hierarchical (multi-index) structure. This helps in breaking down complex data into multiple levels of granularity.\n",
        "\n",
        "**Syntax of Pivot Table in Pandas:**"
      ],
      "metadata": {
        "id": "knMokEc-yZMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.pivot_table(\n",
        "    values=None,\n",
        "    index=None,\n",
        "    columns=None,\n",
        "    aggfunc='mean',\n",
        "    fill_value=None,\n",
        "    margins=False,\n",
        "    margins_name='All'\n",
        ")"
      ],
      "metadata": {
        "id": "DkIlKUSdKmQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "\n",
        "Suppose we have a dataset containing sales data:"
      ],
      "metadata": {
        "id": "Py5xvkxlKqTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Date': ['2025-01-01', '2025-01-01', '2025-01-02', '2025-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Sales': [200, 150, 220, 180]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "pivot_table = df.pivot_table(\n",
        "    values='Sales',\n",
        "    index='Date',\n",
        "    columns='Category',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "print(pivot_table)"
      ],
      "metadata": {
        "id": "Brg4yCeJK1Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benefits of Using Pivot Tables in Pandas:**\n",
        "1. Simplified Data Exploration: Pivot tables help to quickly summarize and explore data by grouping and aggregating it based on certain dimensions.\n",
        "2. Ease of Data Transformation: Pivoting allows you to convert data from a long format into a wide format.\n",
        "3. Improved Analysis: Aggregating data in pivot tables allows you to compare different subsets of the data, such as sales by product category and date, making it easier to spot patterns, trends, or anomalies.\n",
        "4. Multi-Level Grouping: Pivot tables support hierarchical indexing, making it easy to analyze data across multiple levels of grouping.\n",
        "\n",
        "**Advanced Features:**\n",
        "* Multiple Aggregation Functions: We can use multiple aggregation functions to calculate different statistics.\n",
        "* Handling Missing Data: We can use the fill_value parameter to replace NaN values with a specified value, ensuring the pivot table is complete.\n",
        "* Margins: The margins parameter can be used to add \"All\" totals for rows and columns, providing a grand total for each aggregation.\n",
        "\n",
        "Example with Multiple Aggregation Functions:"
      ],
      "metadata": {
        "id": "8XNz-WHaLBo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_table = df.pivot_table(\n",
        "    values='Sales',\n",
        "    index='Date',\n",
        "    columns='Category',\n",
        "    aggfunc=['sum', 'mean'],\n",
        "    fill_value=0\n",
        ")\n",
        "print(pivot_table)"
      ],
      "metadata": {
        "id": "HZ5Y5lVbLdwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 21. Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "**Ans** - NumPy’s array slicing is faster than Python’s list slicing due to several differences in how NumPy arrays and Python lists are implemented and managed in memory.\n",
        "\n",
        "The main reasons of NumPy’s slicing operation is more efficient:\n",
        "\n",
        "1. Contiguous Memory Allocation (NumPy Arrays)\n",
        "* NumPy arrays are stored in contiguous blocks of memory, meaning that the elements of the array are stored next to each other in a single, continuous memory segment. This makes it very efficient to access and slice parts of the array since the memory layout is predictable.\n",
        "* Python lists, on the other hand, are arrays of pointers to objects, which means each element of the list is a reference to a separate object. When slicing a list, Python must access each element individually, which introduces overhead.\n",
        "\n",
        "2. Memory View (NumPy Slicing)\n",
        "* When we slice a NumPy array, it typically does not create a copy of the data but rather returns a view (a reference to the original array). This means that slicing in NumPy does not require memory reallocation, making the operation extremely fast.\n",
        "* In contrast, Python list slicing creates a new list and copies the elements from the original list to the new one. Copying data introduces overhead, which makes slicing slower.\n",
        "\n",
        "3. Optimized Internal Implementation (NumPy)\n",
        "* NumPy is implemented in C and optimized for numerical operations. The low-level C code underlying NumPy operations is highly optimized for performance, particularly when performing array slicing, indexing, and mathematical operations.\n",
        "* Python lists are implemented in Python, which is an interpreted language, and as such, they do not benefit from the same performance optimizations that NumPy arrays do.\n",
        "\n",
        "4. Vectorization (NumPy)\n",
        "* NumPy takes advantage of vectorization to perform operations on entire arrays at once. When slicing a NumPy array, NumPy can directly reference the block of memory without needing to loop through elements, while Python lists would require iterating over each element.\n",
        "* This results in faster slicing since NumPy operations are highly parallelized and optimized for performance.\n",
        "\n",
        "5. Less Overhead for NumPy Operations\n",
        "* NumPy arrays store data in a more efficient format, using smaller and simpler data types compared to Python lists, which store more information for each element (such as type information, references, etc.).\n",
        "* This reduces the overhead in NumPy’s slicing and indexing, making it faster than Python lists, which carry more internal structure.\n",
        "\n",
        "**Differences:**\n",
        "\n",
        "|Feature\t|NumPy Array Slicing\t|Python List Slicing|\n",
        "|----|----|----|\n",
        "|Memory Allocation\t|Contiguous block of memory\t|Non-contiguous, array of pointers|\n",
        "|Return Type\t|View (no copy)\t|New list (copy of data)|\n",
        "|Speed\t|Fast (optimized and direct access)\t|Slower (involves creating a copy)|\n",
        "|Implementation\tWritten in C, |highly optimized\tWritten in Python, |less optimized|\n",
        "|Overhead\t|Minimal, due to efficient data storage and access\t|Higher due to flexible object references|"
      ],
      "metadata": {
        "id": "Y8_Uk1CdycRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 22. What are some common use cases for Seaborn?\n",
        "**Ans** - Seaborn is a powerful Python library for statistical data visualization based on Matplotlib. It provides a high-level interface for creating informative and attractive visualizations with less code, making it especially useful for exploring and understanding data. Here are some common use cases for Seaborn:\n",
        "\n",
        "1. **Exploratory Data Analysis (EDA)**\n",
        "\n",
        "Seaborn is frequently used during the exploratory data analysis phase to quickly visualize data distributions, relationships between variables, and any potential patterns or trends.\n",
        "* Histograms and Kernel Density Estimates (KDEs) to visualize the distribution of a single variable.\n",
        "* Pair plots to visualize pairwise relationships in a dataset.\n",
        "* Box plots and Violin plots to show the distribution of data and detect outliers.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "WO-rxss0yd5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "df = sns.load_dataset('tips')\n",
        "sns.histplot(df['total_bill'], kde=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1YruRFqjOa8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Visualizing Categorical Data**\n",
        "\n",
        "Seaborn provides several functions for visualizing relationships between categorical variables, which is useful when working with qualitative or discrete data.\n",
        "* Bar plots to compare the size of categories.\n",
        "* Box plots and Violin plots to compare distributions across categories.\n",
        "* Count plots to display the frequency of each category.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "NBVDIfnLOfaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='day', y='total_bill', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQbpZ4X1Ot-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Correlation and Heatmaps**\n",
        "\n",
        "Seaborn excels at visualizing correlations and relationships between numeric variables using heatmaps. These are essential in identifying multicollinearity, trends, and patterns in numerical data.\n",
        "* Correlation heatmaps for visualizing correlation matrices of numeric variables.\n",
        "* Cluster maps to visually group variables based on similarity.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "74p1q1qsJJ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EvWyJKySJYVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Regression and Linear Relationships**\n",
        "\n",
        "Seaborn can be used to visualize and analyze the linear relationships between numerical variables, as well as fit regression models.\n",
        "* Scatter plots with regression lines to visualize the relationship between two numeric variables.\n",
        "* Joint plots to visualize relationships between two variables with scatter plots, regression lines, and histograms.\n",
        "* lmplot for fitting and visualizing linear models.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "quiMEq3zJc2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lmplot(x='total_bill', y='tip', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yM7fXSYZJ3fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Facet Grids and Multi-Panel Plots**\n",
        "\n",
        "Seaborn allows you to create multi-plot grids that help you visualize data across multiple subgroups. This is useful for comparing different subsets of your data across categories or numeric values.\n",
        "* FacetGrid for creating grids of subplots based on categorical variables.\n",
        "* PairGrid for visualizing relationships between all combinations of multiple variables.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "GIQ1ExUUKggh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.FacetGrid(df, col=\"time\", row=\"sex\").map(sns.histplot, \"total_bill\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1W7fXueJy6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Visualizing Time Series Data**\n",
        "\n",
        "Seaborn makes it easy to visualize time series data, allowing you to plot trends, seasonality, and other temporal patterns.\n",
        "* Line plots for visualizing time series data.\n",
        "* Rolling averages and trends over time.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "I1Ph2sF9K0sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset('tips')\n",
        "sns.lineplot(x='day', y='total_bill', data=tips)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "alKmvuIjLBRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Heatmaps for Clustered Data**\n",
        "\n",
        "Seaborn’s clustermap function is useful for visualizing hierarchical clustering of rows and columns in datasets. It is particularly useful for gene expression data, financial data, or any data where clustering and similarity are important.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "w2xQwSTBLFOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.clustermap(df.corr(), annot=True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZvRWfBwLM7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Customizing and Aesthetic Control**\n",
        "\n",
        "Seaborn allows for fine control over the aesthetics of the plots, making it suitable for creating publication-quality visualizations.\n",
        "* Customizing colors, styles, and themes.\n",
        "* Adjusting plot elements like axis labels, titles, legends, and ticks.\n",
        "* Seaborn comes with built-in themes that can improve the readability of your plots.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "kXsOHh7bLRZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "sns.boxplot(x=\"day\", y=\"total_bill\", data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YU3fbB8kLd9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **Visualization of Statistical Distributions**\n",
        " Seaborn provides several tools for visualizing the distribution of data and performing statistical analysis.\n",
        "* Distribution plots (distplot) to visualize the distribution of a single variable.\n",
        "* KDE plots to estimate the probability density function of a variable.\n",
        "* Rug plots to show the distribution of data along the x-axis.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "ITQJWCOGLhgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(df['total_bill'], shade=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6zxvsDDSLtGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **Visualization of Multiple Variables**\n",
        "\n",
        "Seaborn can easily visualize interactions between multiple variables, making it an ideal tool for understanding relationships in multi-dimensional data.\n",
        "* Pair plots for visualizing pairwise relationships between multiple numerical features.\n",
        "* Heatmaps and scatterplot matrices to visualize interactions among many variables.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "MckWMYrdLwZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xlwvhh17L8dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "SlNIAt4k3n2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 1. How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "**Ans** - To create a 2D NumPy array and calculate the sum of each row, we can follow these steps:\n",
        "\n",
        "**Steps**:\n",
        "1. Create a 2D NumPy array using np.array() or np.random for random values.\n",
        "2. Use the np.sum() function to calculate the sum of each row along the axis 1 (columns).\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "3mGvAtYZygzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6],\n",
        "                [7, 8, 9]])\n",
        "row_sums = np.sum(arr, axis=1)\n",
        "print(\"Sum of each row:\", row_sums)"
      ],
      "metadata": {
        "id": "hfGugnr0Mt0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 2. Write a Pandas script to find the mean of a specific column in a DataFrame.\n",
        "**Ans** - To find the mean of a specific column in a Pandas DataFrame, we can use the mean() function.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "eUgx91tAykIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "salary_mean = df['Salary'].mean()\n",
        "print(f\"The mean of the 'Salary' column is: {salary_mean}\")"
      ],
      "metadata": {
        "id": "iUUgRAh1NaQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 3. Create a scatter plot using Matplotlib.\n",
        "**Ans** - To create a scatter plot using Matplotlib, we can use the plt.scatter() function.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "A66E6AoTynNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 20, 25, 40, 50]\n",
        "plt.scatter(x, y)\n",
        "plt.title('Simple Scatter Plot')\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TOrFqqExOT-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 4. How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "**Ans** - To calculate the correlation matrix and visualize it using a heatmap with Seaborn, we can follow these steps:\n",
        "\n",
        "**Steps:**\n",
        "1. Calculate the correlation matrix using DataFrame.corr().\n",
        "2. Use seaborn.heatmap() to visualize the correlation matrix as a heatmap.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "l1YGyl4P30wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6],\n",
        "    'D': [9, 7, 5, 3, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wx0L5hD-O1Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 5. Generate a bar plot using Plotly.\n",
        "**Ans** - we can run the following code to generate the bar plot using Plotly.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "Pdllbkg834LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
        "values = [10, 20, 30, 40]\n",
        "fig = go.Figure(data=[go.Bar(x=categories, y=values)])\n",
        "fig.update_layout(\n",
        "    title='Bar Plot using Plotly',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values'\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jNbkDYwyQDO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 6. Create a DataFrame and add a new column based on an existing column.\n",
        "**Ans** - To create a Pandas DataFrame and add a new column based on an existing column,we use these steps:\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "8XKcq5oQ36rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 45]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df['Age_in_10_years'] = df['Age'] + 10\n",
        "print(df)"
      ],
      "metadata": {
        "id": "dYeiSWztQrvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 7. Write a program to perform element-wise multiplication of two NumPy arrays.\n",
        "**Ans** - To perform element-wise multiplication of two NumPy arrays, we can simply use the * operator, which is overloaded in NumPy to perform element-wise operations.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "_TH6Kw6838eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "array1 = np.array([1, 2, 3, 4])\n",
        "array2 = np.array([5, 6, 7, 8])\n",
        "result = array1 * array2\n",
        "print(\"Element-wise multiplication result:\", result)"
      ],
      "metadata": {
        "id": "u_9G1m0ERLvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 8. Create a line plot with multiple lines using Matplotlib.\n",
        "**Ans** - To create a line plot with multiple lines using Matplotlib, we can plot several datasets on the same axes by calling plt.plot() multiple times. Each call to plt.plot() adds a new line to the plot.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "KiYJg4hw3-pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [0, 1, 2, 3, 4, 5]\n",
        "y1 = [0, 1, 4, 9, 16, 25]\n",
        "y2 = [0, -1, -4, -9, -16, -25]\n",
        "plt.plot(x, y1, label='y = x^2', color='blue', marker='o')\n",
        "plt.plot(x, y2, label='y = -x^2', color='red', marker='x')\n",
        "plt.title('Multiple Line Plot Example')\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2gz-yiKQRvRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 9. Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold.\n",
        "**Ans** - To generate a Pandas DataFrame and filter rows where a column value is greater than a specified threshold, we can use conditional indexing.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "9votez1Y4Awx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "threshold = 70000\n",
        "filtered_df = df[df['Salary'] > threshold]\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "gIhq3-1lUD4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 10. Create a histogram using Seaborn to visualize a distribution.\n",
        "**Ans** - To create a histogram using Seaborn to visualize a distribution, we can use the sns.histplot() function. This function automatically generates a histogram for the given data.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "g8OoV59W4C2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "data = [12, 15, 13, 18, 20, 21, 23, 25, 27, 30, 30, 32, 35, 36, 37, 40, 42, 45, 48, 50]\n",
        "sns.histplot(data, kde=True, bins=10, color='blue', edgecolor='black')\n",
        "plt.title('Histogram with Seaborn')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Edc6nFzPU3CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 11. Perform matrix multiplication using NumPy.\n",
        "**Ans** - Matrix multiplication in NumPy can be performed using the np.dot() function or the @ operator.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "R71aL3AK4FLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "matrix1 = np.array([[1, 2],\n",
        "                    [3, 4]])\n",
        "matrix2 = np.array([[5, 6],\n",
        "                    [7, 8]])\n",
        "result = np.dot(matrix1, matrix2)\n",
        "print(\"Matrix Multiplication Result:\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "F3Vj5F-XVkkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 12. Perform matrix multiplication using NumPy.\n",
        "**Ans** - To perform matrix multiplication using NumPy, we can use the np.dot() function or the @ operator for a clean and concise syntax:\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "miZ24n824HFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "matrix1 = np.array([[1, 2],\n",
        "                    [3, 4]])\n",
        "matrix2 = np.array([[5, 6],\n",
        "                    [7, 8]])\n",
        "result = np.dot(matrix1, matrix2)\n",
        "print(\"Matrix Multiplication Result:\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "u5pZ1_FlWwWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 13. Use Pandas to load a CSV file and display its first 5 rows.\n",
        "**Ans** - To load a CSV file using Pandas and display its first 5 rows, we can use the pd.read_csv() function to read the CSV file and the head() method to display the first few rows.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "6d4HNFP04JEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('your_file.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "zAcV5RlgX08p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "1. pd.read_csv('your_file.csv'): This function reads the CSV file and loads its contents into a Pandas DataFrame. We should replace 'your_file.csv' with the actual path to our CSV file.\n",
        "2. df.head(): This method returns the first 5 rows of the DataFrame by default. We can pass a different number to head(), for example, df.head(10) to view the first 10 rows.\n",
        "\n",
        "**Example Output:**\n",
        "\n",
        "If our CSV file looks like this:"
      ],
      "metadata": {
        "id": "qlGu7oZnX57y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Name,Age,Salary\n",
        "Alice,25,50000\n",
        "Bob,30,60000\n",
        "Charlie,35,70000\n",
        "David,40,80000\n",
        "Eva,45,90000"
      ],
      "metadata": {
        "id": "VMqoF4hfYSv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output will be:"
      ],
      "metadata": {
        "id": "nTEtlFA-YZ46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "      Name  Age  Salary\n",
        "0    Alice   25   50000\n",
        "1      Bob   30   60000\n",
        "2  Charlie   35   70000\n",
        "3    David   40   80000\n",
        "4      Eva   45   90000"
      ],
      "metadata": {
        "id": "7Ra1eW6tYeAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 14. Create a 3D scatter plot using Plotly.\n",
        "**Ans** - To create a 3D scatter plot using Plotly, we can use the plotly.graph_objects module and the go.Scatter3d function to create a 3D scatter plot.\n",
        "\n",
        "**Example:**"
      ],
      "metadata": {
        "id": "XEc9EmRv4-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [5, 4, 3, 2, 1]\n",
        "z = [1, 3, 5, 7, 9]\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=x,\n",
        "    y=y,\n",
        "    z=z,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=10,\n",
        "        color=z,\n",
        "        colorscale='Viridis',\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot Example',\n",
        "    scene=dict(\n",
        "        xaxis_title='X Axis',\n",
        "        yaxis_title='Y Axis',\n",
        "        zaxis_title='Z Axis'\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EkRk8SJSY19K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}